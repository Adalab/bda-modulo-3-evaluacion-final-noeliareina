{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✈️ Análisis de Clientes y Vuelos de la Aerolínea  \n",
    "\n",
    "Objetivo  \n",
    "\n",
    "**En este análisis exploraremos los datos de clientes inscritos en una membresía de aerolínea y sus vuelos.**\n",
    "\n",
    "  **Realizaremos limpieza, visualización y evaluación de los datos para obtener insights relevantes.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# antes de empezar la lección tendremos que instalarunas librerías. Para ello tendreis que descomentar (una a una) la linea de abajo y ejecutar la celda\n",
    "#!pip install scikit-learn\n",
    "#!pip install seaborn\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar más adelante los df\n",
    "# df_completo = df_loyalty.merge(df_flight, on=\"loyalty_number\", how=\"inner\")\n",
    "# Esto combina la información del cliente con sus vuelos.\n",
    "# Si hay clientes sin vuelos registrados, puedes usar how='left' en lugar de inner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 1: Exploración y Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 📌 1. Configuración para gestión de nulos\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# 📌 2. Configurar pandas para ver todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# 📌 3. Configuración para gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro, poisson, chisquare, expon, kstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loyalty Number</th>\n",
       "      <th>Country</th>\n",
       "      <th>Province</th>\n",
       "      <th>City</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Loyalty Card</th>\n",
       "      <th>CLV</th>\n",
       "      <th>Enrollment Type</th>\n",
       "      <th>Enrollment Year</th>\n",
       "      <th>Enrollment Month</th>\n",
       "      <th>Cancellation Year</th>\n",
       "      <th>Cancellation Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16732</th>\n",
       "      <td>823768</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>V6E 3Z3</td>\n",
       "      <td>Female</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>61850.19</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2012</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16733</th>\n",
       "      <td>680886</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Saskatchewan</td>\n",
       "      <td>Regina</td>\n",
       "      <td>S1J 3C5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>89210.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>67907.27</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2014</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16734</th>\n",
       "      <td>776187</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>V5R 1W3</td>\n",
       "      <td>Male</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Single</td>\n",
       "      <td>Star</td>\n",
       "      <td>74228.52</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16735</th>\n",
       "      <td>906428</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Yukon</td>\n",
       "      <td>Whitehorse</td>\n",
       "      <td>Y2K 6R0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>-57297.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>10018.66</td>\n",
       "      <td>2018 Promotion</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16736</th>\n",
       "      <td>652627</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>R2C 0M5</td>\n",
       "      <td>Female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>75049.0</td>\n",
       "      <td>Married</td>\n",
       "      <td>Star</td>\n",
       "      <td>83325.38</td>\n",
       "      <td>Standard</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Loyalty Number Country          Province        City Postal Code  \\\n",
       "16732          823768  Canada  British Columbia   Vancouver     V6E 3Z3   \n",
       "16733          680886  Canada      Saskatchewan      Regina     S1J 3C5   \n",
       "16734          776187  Canada  British Columbia   Vancouver     V5R 1W3   \n",
       "16735          906428  Canada             Yukon  Whitehorse     Y2K 6R0   \n",
       "16736          652627  Canada          Manitoba    Winnipeg     R2C 0M5   \n",
       "\n",
       "       Gender Education   Salary Marital Status Loyalty Card       CLV  \\\n",
       "16732  Female   College      NaN        Married         Star  61850.19   \n",
       "16733  Female  Bachelor  89210.0        Married         Star  67907.27   \n",
       "16734    Male   College      NaN         Single         Star  74228.52   \n",
       "16735    Male  Bachelor -57297.0        Married         Star  10018.66   \n",
       "16736  Female  Bachelor  75049.0        Married         Star  83325.38   \n",
       "\n",
       "      Enrollment Type  Enrollment Year  Enrollment Month  Cancellation Year  \\\n",
       "16732        Standard             2012                12                NaN   \n",
       "16733        Standard             2014                 9                NaN   \n",
       "16734        Standard             2014                 3                NaN   \n",
       "16735  2018 Promotion             2018                 4                NaN   \n",
       "16736        Standard             2015                12             2016.0   \n",
       "\n",
       "       Cancellation Month  \n",
       "16732                 NaN  \n",
       "16733                 NaN  \n",
       "16734                 NaN  \n",
       "16735                 NaN  \n",
       "16736                 8.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Cargar el dataset de la información de los clientes sin la columna \"Unnamed: 0\"\n",
    "df_loyalty = pd.read_csv(\"Customer_Loyalty_History.csv\")\n",
    "# Vista previa de los datos\n",
    "display(df_loyalty.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carga y Exploración Inicial de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loyalty Number</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Flights Booked</th>\n",
       "      <th>Flights with Companions</th>\n",
       "      <th>Total Flights</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Points Accumulated</th>\n",
       "      <th>Points Redeemed</th>\n",
       "      <th>Dollar Cost Points Redeemed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100018</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1521</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100102</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2030</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100140</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1200</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100214</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100272</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Loyalty Number  Year  Month  Flights Booked  Flights with Companions  \\\n",
       "0          100018  2017      1               3                        0   \n",
       "1          100102  2017      1              10                        4   \n",
       "2          100140  2017      1               6                        0   \n",
       "3          100214  2017      1               0                        0   \n",
       "4          100272  2017      1               0                        0   \n",
       "\n",
       "   Total Flights  Distance  Points Accumulated  Points Redeemed  \\\n",
       "0              3      1521               152.0                0   \n",
       "1             14      2030               203.0                0   \n",
       "2              6      1200               120.0                0   \n",
       "3              0         0                 0.0                0   \n",
       "4              0         0                 0.0                0   \n",
       "\n",
       "   Dollar Cost Points Redeemed  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Cargar el dataset de la información de la actividad de los vuelos de los clientes sin la columna \"Unnamed: 0\"\n",
    "df_flight = pd.read_csv(\"Customer_Flight_Activity.csv\")\n",
    "# Vista previa de los datos\n",
    "display(df_flight.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploración Inicial:\n",
    "- Realiza una exploración inicial de los datos para identificar posibles problemas, como valores nulos, atípicos o datos faltantes en las columnas relevantes\n",
    "- Utiliza funciones de Pandas para obtener información sobre la estructura de los datos, la presencia de valores nulos y estadísticas básicas de las columnas involucradas.\n",
    "- Une los dos conjuntos de datos de la forma más eficiente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comenzamos viendo la información de el csv de los datos de los clientes:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de clientes: (16737, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamaño del dataset de clientes: {df_loyalty.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset de vuelos: (405624, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tamaño del dataset de vuelos: {df_flight.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16737 entries, 0 to 16736\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Loyalty Number      16737 non-null  int64  \n",
      " 1   Country             16737 non-null  object \n",
      " 2   Province            16737 non-null  object \n",
      " 3   City                16737 non-null  object \n",
      " 4   Postal Code         16737 non-null  object \n",
      " 5   Gender              16737 non-null  object \n",
      " 6   Education           16737 non-null  object \n",
      " 7   Salary              12499 non-null  float64\n",
      " 8   Marital Status      16737 non-null  object \n",
      " 9   Loyalty Card        16737 non-null  object \n",
      " 10  CLV                 16737 non-null  float64\n",
      " 11  Enrollment Type     16737 non-null  object \n",
      " 12  Enrollment Year     16737 non-null  int64  \n",
      " 13  Enrollment Month    16737 non-null  int64  \n",
      " 14  Cancellation Year   2067 non-null   float64\n",
      " 15  Cancellation Month  2067 non-null   float64\n",
      "dtypes: float64(4), int64(3), object(9)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Información general de variables en dataset de clientes\n",
    "df_loyalty.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 405624 entries, 0 to 405623\n",
      "Data columns (total 10 columns):\n",
      " #   Column                       Non-Null Count   Dtype  \n",
      "---  ------                       --------------   -----  \n",
      " 0   Loyalty Number               405624 non-null  int64  \n",
      " 1   Year                         405624 non-null  int64  \n",
      " 2   Month                        405624 non-null  int64  \n",
      " 3   Flights Booked               405624 non-null  int64  \n",
      " 4   Flights with Companions      405624 non-null  int64  \n",
      " 5   Total Flights                405624 non-null  int64  \n",
      " 6   Distance                     405624 non-null  int64  \n",
      " 7   Points Accumulated           405624 non-null  float64\n",
      " 8   Points Redeemed              405624 non-null  int64  \n",
      " 9   Dollar Cost Points Redeemed  405624 non-null  int64  \n",
      "dtypes: float64(1), int64(9)\n",
      "memory usage: 30.9 MB\n"
     ]
    }
   ],
   "source": [
    "# Información general de variables en dataset de vuelos\n",
    "df_flight.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Limpieza de los datos\n",
    "- Elimina o trata los valores nulos, si los hay, en las columnas clave para asegurar que los datos\n",
    "estén completos.\n",
    "- Verifica la consistencia y corrección de los datos para asegurarte de que los datos se\n",
    "presenten de forma coherente.\n",
    "- Realiza cualquier ajuste o conversión necesaria en las columnas (por ejemplo, cambiar tipos de datos) para garantizar la adecuación de los datos para el análisis estadístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de los datos de clientes (df_loyalty) y vuelos (df_flights)\n",
    "\n",
    "- Vamos a estandarizar los datos. Primero, vemos que los nombres de las columnas empiezan con mayúsculas, todos los nombres de las columnas se cambiarán a minúsculas. \n",
    "-Modificaremos los nombres de las variables de cada dataset, es decir, cambiaremos los nombres de las columnas eliminando espacios y comas.\n",
    "\n",
    "???????\n",
    "- Haciendo el análisis exploratorio nos hemos dado cuenta de que algunas de las variables (`xxxx`, `oooo`) no son del tipo que deberían. Esto es debido a que los decimales están establecidos como comas y no con puntos. Crea una función que nos permita cambiar esas comas por puntos para que los datos tengan el tipo correcto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tras renombrar columnas: Index(['loyalty_id', 'country', 'province', 'city', 'postal_code', 'gender',\n",
      "       'education', 'salary', 'marital_status', 'loyalty_card', 'clv',\n",
      "       'enrollment_type', 'enrollment_year', 'enrollment_month',\n",
      "       'cancellation_year', 'cancellation_month'],\n",
      "      dtype='object')\n",
      "Tras renombrar columnas: Index(['loyalty_id', 'year', 'month', 'flights_booked',\n",
      "       'flights_with_companions', 'total_flights', 'distance',\n",
      "       'points_accumulated', 'points_redeemed', 'dollar_cost_points_redeemed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Convertir nombres de columnas a minúsculas y reemplazar espacios por '_'\n",
    "df_loyalty.columns = df_loyalty.columns.str.lower().str.replace(\" \", \"_\")\n",
    "df_flight.columns = df_flight.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "# Es importante también que renombremos la variable del id del cliente \"Loyalty Number\"\n",
    "# Para ello:\n",
    "df_loyalty.rename(columns={\"Loyalty Number\": \"loyalty_id\"}, inplace=True)\n",
    "df_flight.rename(columns={\"Loyalty Number\": \"loyalty_id\"}, inplace=True)\n",
    "\n",
    "print(f\"Tras renombrar columnas: {df_loyalty.columns}\")\n",
    "print(f\"Tras renombrar columnas: {df_flight.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ¿Hay duplicados en Loyalty Number, variable común entre los dos datasets?\n",
    "df_loyalty[\"loyalty_id\"].isnull().sum(), df_flight[\"loyalty_id\"].isnull().sum()\n",
    "# Respuesta: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número mínimo de cliente en el dataset de loyalty es: 100018\n",
      "El número máximo de cliente en el dataset de loyalty es: 999986\n",
      "--------------------------------------------------\n",
      "El número mínimo de cliente en el dataset de flight es: 100018\n",
      "El número máximo de cliente en el dataset de flight es: 999986\n"
     ]
    }
   ],
   "source": [
    "# Observación de los datos\n",
    "'''df_loyalty'''\n",
    "client_number_min = df_loyalty[\"loyalty_id\"].min()\n",
    "print(f\"El número mínimo de cliente en el dataset de loyalty es: {client_number_min}\")\n",
    "client_number_max = df_loyalty[\"loyalty_id\"].max()\n",
    "print(f\"El número máximo de cliente en el dataset de loyalty es: {client_number_max}\")\n",
    "# No hay valores  negativos en la variable \"loyalty_number\" y no hay duplicados.\n",
    "\n",
    "print(\"-\"*50)\n",
    "'''df_flight'''\n",
    "flightclient_number_min = df_flight[\"loyalty_id\"].min()\n",
    "print(f\"El número mínimo de cliente en el dataset de flight es: {flightclient_number_min}\")\n",
    "flightclient_number_max = df_flight[\"loyalty_id\"].max()\n",
    "print(f\"El número máximo de cliente en el dataset de flight es: {flightclient_number_max}\")\n",
    "\n",
    "# No hay valores  negativos en la variable \"loyalty_number\" y no hay duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('int64'), dtype('int64'))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loyalty[\"loyalty_id\"].dtype, df_flight[\"loyalty_id\"].dtype\n",
    "# Respuesta: Ambos son integers, por lo que no es necesario convertirlos a otro tipo de dato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Comprobamos si hay valores nulos o negativos en los datos de clientes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loyalty_number            0\n",
       "country                   0\n",
       "province                  0\n",
       "city                      0\n",
       "postal_code               0\n",
       "gender                    0\n",
       "education                 0\n",
       "salary                 4238\n",
       "marital_status            0\n",
       "loyalty_card              0\n",
       "clv                       0\n",
       "enrollment_type           0\n",
       "enrollment_year           0\n",
       "enrollment_month          0\n",
       "cancellation_year     14670\n",
       "cancellation_month    14670\n",
       "dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loyalty.isna().sum()\n",
    "# Parece que las columnas \"salary\" \"cancellation_year\" y \"cancellation_month\" tiene valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**salary**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4238"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loyalty[\"salary\"].isnull().sum()\n",
    "# total de nulos en el dataset de clientes\n",
    "# salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El rango de salary es {df_loyalty[\"salary\"].index}\")\n",
    "# 16736 - 4238 nulos = 12499 son datos no nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El porcentaje de nulos en el dataset de clientes es: loyalty_number         0.000000\n",
      "country                0.000000\n",
      "province               0.000000\n",
      "city                   0.000000\n",
      "postal_code            0.000000\n",
      "gender                 0.000000\n",
      "education              0.000000\n",
      "salary                25.321145\n",
      "marital_status         0.000000\n",
      "loyalty_card           0.000000\n",
      "clv                    0.000000\n",
      "enrollment_type        0.000000\n",
      "enrollment_year        0.000000\n",
      "enrollment_month       0.000000\n",
      "cancellation_year     87.650117\n",
      "cancellation_month    87.650117\n",
      "dtype: float64\n",
      "Es más del 20 % de los datos\n"
     ]
    }
   ],
   "source": [
    "# Vamos a ver el porcentaje\n",
    "porc_nulos = (df_loyalty.isnull().sum() / df_loyalty.shape[0]) * 100\n",
    "print(f\"El porcentaje de nulos en el dataset de clientes es: {porc_nulos}\")\n",
    "print(\"Es más del 20 % de los datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gestionamos los valores nulos, ya que no podemos tener un salario nulo*\n",
    "*Después vamos a ver los valores negativos a positivos, ya que no tiene sentido que un cliente tenga un salario negativo. Tenemos que considerar si se vuelven nulos o se vuelven positivos*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Eliminar NaN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.321144769074504"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Porcentaje exacto de valores nulos en \"salary\"\n",
    "nan_porcent = df_loyalty[\"salary\"].isnull().mean() * 100\n",
    "nan_porcent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La mediana de salary es: 73455.0\n"
     ]
    }
   ],
   "source": [
    "# Lo más adecuado sería imputar por la mediana tales datos\n",
    "# ya que un 25% es un valor significativo de nulos para eliminar\n",
    "# y la media puede estar sesgada por los outliers\n",
    "mediana = df_loyalty[\"salary\"].median()\n",
    "print(f\"La mediana de salary es: {mediana}\")\n",
    "# Imputando los valores nulos de \"salary\" por la mediana\n",
    "df_loyalty[\"salary\"].fillna(mediana, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loyalty_number            0\n",
       "country                   0\n",
       "province                  0\n",
       "city                      0\n",
       "postal_code               0\n",
       "gender                    0\n",
       "education                 0\n",
       "salary                    0\n",
       "marital_status            0\n",
       "loyalty_card              0\n",
       "clv                       0\n",
       "enrollment_type           0\n",
       "enrollment_year           0\n",
       "enrollment_month          0\n",
       "cancellation_year     14670\n",
       "cancellation_month    14670\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comprobamos los cambios\n",
    "df_loyalty.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Cambio valores negativos a positivos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loyalty[\"salary\"].dtype\n",
    "# Se ha mantenido el salario como tipo float para permitir un análisis estadístico más preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     16737.000000\n",
       "mean      77864.294198\n",
       "std       30138.879584\n",
       "min        9081.000000\n",
       "25%       63899.000000\n",
       "50%       73455.000000\n",
       "75%       82940.000000\n",
       "max      407228.000000\n",
       "Name: salary, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos los datos estadísticos de la columna \"salary\"\n",
    "df_loyalty[\"salary\"].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9081.0 407228.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# ¿Hay valores negativos?\n",
    "print(df_loyalty[\"salary\"].min(), df_loyalty[\"salary\"].max())\n",
    "# Encontramos valores negativos en la columna \"salary\" y valores nulos\n",
    "# Vamos a ver cuántos valores negativos hay\n",
    "print(df_loyalty[df_loyalty[\"salary\"] < 0].shape[0])  # 20 valores negativos a modificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9081.0 407228.0\n"
     ]
    }
   ],
   "source": [
    "# Convertimos a valores absolutos los negativos\n",
    "''' Consideramos que la mejor opción es convertir los valores negativos\n",
    " a positivos ya que los datos así tendrían sentido.'''\n",
    "df_loyalty[\"salary\"] = df_loyalty[\"salary\"].abs()\n",
    "# Comprobamos que no hay valores negativos\n",
    "print(df_loyalty[\"salary\"].min(), df_loyalty[\"salary\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_loyalty[\"salary\"] < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Más valores numéricos de df_loyalty: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Variables numéricas Index(['loyalty_number', 'salary', 'clv', 'enrollment_year',\n",
      "       'enrollment_month', 'cancellation_year', 'cancellation_month'],\n",
      "      dtype='object')\n",
      " Variables categóricas Index(['country', 'province', 'city', 'postal_code', 'gender', 'education',\n",
      "       'marital_status', 'loyalty_card', 'enrollment_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "# Definimos la lista los nombres de las variables numéricas \n",
    "numericas = df_loyalty.select_dtypes(include = np.number).columns\n",
    "print(f\" Variables numéricas {numericas}\")\n",
    "# Definimos la lista de las variables categóricas\n",
    "categoricas = df_loyalty.select_dtypes(include = \"object\").columns\n",
    "print(f\" Variables categóricas {categoricas}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customer Lifetime Value**: **clv** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Verificar valores únicos en variables categóricas\n",
    "Antes de seguir con la limpieza, verifica qué valores\n",
    " hay en las variables categóricas para ver si necesitan ajustes:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores únicos en gender: ['Female' 'Male']\n",
      "Valores únicos en education: ['Bachelor' 'College' 'Master' 'High School or Below' 'Doctor']\n",
      "Valores únicos en marital_status: ['Married' 'Divorced' 'Single']\n",
      "Valores únicos en loyalty_card: ['Star' 'Aurora' 'Nova']\n",
      "Valores únicos en enrollment_type: ['Standard' '2018 Promotion']\n"
     ]
    }
   ],
   "source": [
    "categoricas = [\"gender\", \"education\", \"marital_status\", \"loyalty_card\", \"enrollment_type\"]\n",
    "for col in categoricas:\n",
    "    print(f\"Valores únicos en {col}: {df_loyalty[col].unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(colums= {‘key’: ‘value’}, index= {‘key’: ‘value’}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict comprehension para unificar nombres de todas las columnas del DataFrame: \n",
    "# Modifica en todos los valores de la columna sustituyendo el . por espacio.\n",
    "df.columns = df.columns.str.lower()\n",
    "1. nuevas_columnas = {columna: columna.lower().replace(\".\", \"\") for columna \n",
    "in df.columns} \n",
    "2. df.rename(columns = nuevas_columnas, inplace = True) \n",
    "#Modifica todas las columnas poniendo sus nombres en minúsculas y sustituye el . \n",
    "#por nada, para que el nombre de la columna vaya todo junto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = [\"price\", \"reference_price\"] #cambio de title del 0 por el 1 índice\n",
    "\n",
    "for col in columnas:\n",
    "    df_unido[col] = df_unido[col].apply(cambiar_float) #aplicamos la función a cada columna con el bucle de iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cambiar_float(dato):\n",
    "\ttry:\n",
    "\t\treturn float(dato.replace(\",\", \".\"))\n",
    "\texcept:\n",
    "\t\treturn np.nan\n",
    "\n",
    "x = \"2,3\"\n",
    "\n",
    "cambiar_float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cambiar tipo de valor de una columna.  \n",
    "Modificarlo a tipo fecha: \n",
    "df[‘columna’] = pd.to_datetime(df[‘columna’])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para reemplazar comas por puntos y convertir a float\n",
    "def corregir_decimales(df, columnas):\n",
    "    for col in columnas:\n",
    "        df[col] = df[col].astype(str).str.replace(\",\", \".\", regex=False)  # Reemplazar comas por puntos\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")  # Convertir a float, coerce valores no numéricos a NaN\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores únicos en variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_categ = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a ver que columnas tienen valores nulos\n",
    "porcentajes_nulos = (df.isnull().sum()[df.isna().sum() > 0] / df.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos estadísticos de la columnas numéricas\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos estadísticos de la columnas categóricas\n",
    "df.describe(include = \"object\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productos[\"name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar si hay filas duplicadas\n",
    "duplicados = df.duplicated().sum()\n",
    "df_productos[df_productos.duplicated(subset=\"product_id\", keep=False)].sort_values(\"product_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod_no_dup.drop(columns=[\"description\"], inplace=True)\n",
    "df_prod_no_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido = df_precios.merge(df_prod_no_dup, on= [\"product_id\"], how=\"left\")\n",
    "df_unido.head()\n",
    "\n",
    "df_unido.drop(columns=[\"supermarket\"], inplace=True)\n",
    "df_unido.head()\n",
    "\n",
    "df_unido.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Operadores de comparación: >, <, >=, <=, ==, != \n",
    "Crear  una  condición  y  aplicarla  a  columnas.  Se  pueden  aplicar  diferentes \n",
    "condiciones con & o |. '''\n",
    "#1. Crear condición: \n",
    "condición = df[‘columna’] == ‘x’ \n",
    "#2. Aplicar condición \n",
    "df_nuevo = df[condición] \n",
    "#3. df_nuevo es igual pero con la columna de la condición modificada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "isin(): seleccionar filas que contienen valores específicos en una columna. Un valor \n",
    "o lista de valores \n",
    "df[‘columna’].isin(valores) \n",
    "1. Crear filtro: filtro = [‘valor1’, ‘valor2’] \n",
    "2. Aplicar filtro df_nuevo = df[df[‘columna’].isin(filtro)] \n",
    "3. df_nuevo es igual pero con las filas que contienen los valores del filtro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "between(): filtrar por un rango \n",
    "nuevo_df = df[df[‘columna’].between(inicio, fin, inclusive=both/left/right/neither)] \n",
    "• both: incluye los valores de inicio y fin \n",
    "• left: incluye inicio pero no fin \n",
    "• right: incluye fin pero no inicio \n",
    "• neither: no incluye ni inicio ni fin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "str.contains(): filtrar por palabras. Devuelve un booleano. \n",
    "df[‘columna’].str.contains(pat, case=True, na=nan, regex=True) \n",
    "• pat: patrón de texto a buscar \n",
    "• case: (op) True distingue mayúsculas y minúsculas \n",
    "• na=nan: (op) \n",
    "• regex: (op) True se interpreta como regex "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupación de columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operaciones de agregación: \n",
    ".count(): número valores no nulos \n",
    ".describe(): resumen de los principales estadísticos \n",
    ".sum(): suma de todos los valores \n",
    ".mean(): media de los valores \n",
    ".median(): mediana. Ordenados de menor a mayor, valor que queda en la mitad \n",
    ".min(): valor mínimo \n",
    ".max(): valor máximo \n",
    ".std(): desviación estándar. Cuánto se desvían los valores de la media. \n",
    ".var(): varianza. Cuánto se desvían los valores de la media al cuadrado.\n",
    "\n",
    "\n",
    "Sintaxis: \n",
    "Para una operación \n",
    "variable = df.groupby(columna)[columna_operacion].operacion \n",
    "Para varias operaciones \n",
    "variable = df.groupby(columna)[columna_operacion].agg([‘op1’, ‘op2’])\n",
    "\n",
    "Métodos: \n",
    ".reset_index(): nuevo DataFrame del resultado con índice en 0 \n",
    "df.groupby(columna)[columna_operacion].operacion(numeric_only=True):  aplica \n",
    "la operación a todas columnas numéricas \n",
    "variable_agrupacion.ngroups: grupos formados después de la agrupación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar una función a una columna. Se puede añadir a una nueva columna de \n",
    "o aplica a una columna ya existente para modificar el DataFrame \n",
    "Sintaxis: \n",
    "df[‘nueva_columna’] = df[‘columna’].apply(función) \n",
    "df[‘columna_modificar’] = df[‘columna_modificar’].apply(función)\n",
    "Para aplicar una función que debe recibir dos parámetros (dos columnas del DF) se \n",
    "hace con lambda. \n",
    "Sintaxis: \n",
    "df[‘nueva_columna’] = df.apply(lambda x: función(x[‘col1’], x[‘col2’]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OTROS MÉTODOS DE LIMPIEZA \n",
    " \n",
    "Para  aplicar  una  transformación  o  reemplazo  de  los  valores  a  un  Serie  o \n",
    "DataFrame \n",
    " \n",
    ".map(): transformación de cada elemento de una Serie \n",
    "Pasos:  \n",
    "1. Crear diccionario de mapeo, keys valores actuales, values valores por los \n",
    "que reemplazar \n",
    "diccionario = {0: \"No\", 1: \"Si\"} \n",
    "2. Aplicar diccionario a una columna: \n",
    "df[‘col’] = df[‘col’].map(diccionario) \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    ".replace(): reemplaza valores en un DataFrame o Serie por otros especificados \n",
    "Sintaxis: \n",
    "df[‘col’] = df[‘col’].replace(valor a reemplazar, nuevo valor) \n",
    "Se utiliza para reemplazar un valor concreto de esa columna, no todos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fase 2: Visualización"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
